"""
AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿå®‰è£…æ–‡æ¡£


1. ç¯å¢ƒè¦æ±‚ï¼š
   - Python 3.7+
   - pip (PythonåŒ…ç®¡ç†å™¨)

2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ä½†æ¨èï¼‰ï¼š
   python -m venv venv
   source venv/bin/activate  # åœ¨Windowsä¸Šä½¿ç”¨: venv\Scripts\activate

3. å®‰è£…ä¾èµ–ï¼š
   pip install -r requirements.txt

4. requirements.txt æ–‡ä»¶å†…å®¹ï¼š
altair==5.4.1
annotated-types==0.7.0
anyio==4.4.0
attrs==24.2.0
blinker==1.8.2
cachetools==5.5.0
certifi==2024.8.30
charset-normalizer==3.3.2
click==8.1.7
distro==1.9.0
faiss-cpu==1.8.0.post1
filelock==3.16.1
Flask==3.0.3
fsspec==2024.9.0
gitdb==4.0.11
GitPython==3.1.43
google-api-core==2.19.2
google-api-python-client==2.146.0
google-auth==2.34.0
google-auth-httplib2==0.2.0
google_search_results==2.4.2
googleapis-common-protos==1.65.0
h11==0.14.0
httpcore==1.0.5
httplib2==0.22.0
httpx==0.27.2
huggingface-hub==0.25.0
idna==3.10
itsdangerous==2.2.0
jieba==0.42.1
Jinja2==3.1.4
jiter==0.5.0
joblib==1.4.2
jsonschema==4.23.0
jsonschema-specifications==2023.12.1
lxml==5.3.0
markdown-it-py==3.0.0
MarkupSafe==2.1.5
mdurl==0.1.2
mpmath==1.3.0
narwhals==1.8.1
networkx==3.3
numpy==1.26.4
openai==1.46.0
packaging==24.1
pandas==2.2.2
pillow==10.4.0
proto-plus==1.24.0
protobuf==5.28.1
pyarrow==17.0.0
pyasn1==0.6.1
pyasn1_modules==0.4.1
PyAudio==0.2.11
pydantic==2.9.2
pydantic_core==2.23.4
pydeck==0.9.1
Pygments==2.18.0
pyparsing==3.1.4
PyPDF2==3.0.1
python-dateutil==2.9.0.post0
python-docx==1.1.2
pytz==2024.2
PyYAML==6.0.2
referencing==0.35.1
regex==2024.9.11
requests==2.32.3
rich==13.8.1
rpds-py==0.20.0
rsa==4.9
safetensors==0.4.5
scikit-learn==1.5.2
scipy==1.14.1
sentence-transformers==3.1.0
six==1.16.0
smmap==5.0.1
sniffio==1.3.1
SpeechRecognition==3.10.4
streamlit==1.38.0
sympy==1.13.2
tenacity==8.5.0
threadpoolctl==3.5.0
tiktoken==0.7.0
tokenizers==0.19.1
toml==0.10.2
torch==2.2.2
tornado==6.4.1
tqdm==4.66.5
transformers==4.44.2
typing_extensions==4.12.2
tzdata==2024.1
uritemplate==4.1.1
urllib3==2.2.3
Werkzeug==3.0.4


5. å…¶ä»–ä¾èµ–ï¼š
   - ç¡®ä¿ä½ æœ‰æœ‰æ•ˆçš„OpenAI APIå¯†é’¥
   - å¦‚æœä½¿ç”¨Googleæœç´¢åŠŸèƒ½ï¼Œéœ€è¦æœ‰æ•ˆçš„SerpAPIå¯†é’¥
   - å¯¹äºè¯­éŸ³è¯†åˆ«åŠŸèƒ½ï¼Œéœ€è¦å®‰è£…ç³»ç»Ÿçº§ä¾èµ– PortAudioã€‚è¿™åœ¨æŸäº›æ‰˜ç®¡ç¯å¢ƒï¼ˆå¦‚ Streamlit Cloudï¼‰ä¸­å¯èƒ½æ— æ³•ç›´æ¥å®‰è£…ã€‚
     å¦‚æœåœ¨æ‰˜ç®¡ç¯å¢ƒä¸­é‡åˆ°é—®é¢˜ï¼Œå¯èƒ½éœ€è¦è€ƒè™‘ä½¿ç”¨åŸºäºæµè§ˆå™¨çš„è¯­éŸ³è¯†åˆ«æ–¹æ¡ˆæˆ–äº‘ç«¯è¯­éŸ³è¯†åˆ«æœåŠ¡ã€‚
   - å¯¹äºå¤§å‹æ–‡ä»¶å¤„ç†ï¼Œå¯èƒ½éœ€è¦å¢åŠ ç³»ç»Ÿå†…å­˜æˆ–ä½¿ç”¨æ›´å¼ºå¤§çš„ç¡¬ä»¶

6. è¿è¡Œåº”ç”¨ï¼š
   streamlit run app.py

æ³¨æ„ï¼š
- è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–éƒ½å·²æ­£ç¡®å®‰è£…
- åœ¨ä»£ç ä¸­æ›¿æ¢OpenAI APIå¯†é’¥å’ŒSerpAPIå¯†é’¥ä¸ºä½ è‡ªå·±çš„å¯†é’¥
- å¯¹äºè¯­éŸ³è¯†åˆ«åŠŸèƒ½ï¼Œéœ€è¦å®‰è£…ç³»ç»Ÿçº§ä¾èµ– PortAudioã€‚è¿™åœ¨æŸäº›æ‰˜ç®¡ç¯å¢ƒï¼ˆå¦‚ Streamlit Cloudï¼‰ä¸­å¯èƒ½æ— æ³•ç›´æ¥å®‰è£…ã€‚
  å¦‚æœåœ¨æ‰˜ç®¡ç¯å¢ƒä¸­é‡åˆ°é—®é¢˜ï¼Œå¯èƒ½éœ€è¦è€ƒè™‘ä½¿ç”¨åŸºäºæµè§ˆå™¨çš„è¯­éŸ³è¯†åˆ«æ–¹æ¡ˆæˆ–äº‘ç«¯è¯­éŸ³è¯†åˆ«æœåŠ¡ã€‚
- å¯¹äºå¤§å‹æ–‡ä»¶å¤„ç†ï¼Œå¯èƒ½éœ€è¦å¢åŠ ç³»ç»Ÿå†…å­˜æˆ–ä½¿ç”¨æ›´å¼ºå¤§çš„ç¡¬ä»¶
"""

import streamlit as st

# è®¾ç½®é¡µé¢é…ç½®å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
st.set_page_config(
    page_title="AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items=None
)

# éšè— Streamlit é»˜è®¤çš„èœå•ã€é¡µè„šå’Œ Deploy æŒ‰é’®
hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display: none;}
    header {visibility: hidden;}
    </style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

from openai import OpenAI
from sentence_transformers import SentenceTransformer
import multiprocessing
import PyPDF2
import docx
import faiss
import tiktoken
import os
import pickle
import numpy as np
import jieba
from collections import Counter
import sqlite3
import pandas as pd
from serpapi import GoogleSearch
import requests
import io
import speech_recognition as sr
import streamlit.components.v1 as components
import time

# åˆå§‹åŒ–
client = OpenAI(
    api_key="sk-1pUmQlsIkgla3CuvKTgCrzDZ3r0pBxO608YJvIHCN18lvOrn",
    base_url="https://api.chatanywhere.tech/v1"
)

@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

model = load_model()

# è®¡ç®—tokenæ•°é‡
def num_tokens_from_string(string: str) -> int:
    encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
    return len(encoding.encode(string))

# æ–‡æ¡£å‘é‡åŒ–æ¨¡å—
def vectorize_document(file, max_tokens):
    text = ""
    if file.type == "application/pdf":
        pdf_reader = PyPDF2.PdfReader(file)
        for page in pdf_reader.pages:
            text += page.extract_text()
    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = docx.Document(file)
        for para in doc.paragraphs:
            text += para.text + "\n"
    else:
        text = file.getvalue().decode("utf-8")
    
    chunks = []
    current_chunk = ""
    for sentence in text.split('.'):
        if num_tokens_from_string(current_chunk + sentence) > max_tokens:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = sentence
        else:
            current_chunk += sentence + '.'
    if current_chunk:
        chunks.append(current_chunk)
    
    vectors = model.encode(chunks)
    index = faiss.IndexFlatL2(384)  # 384æ˜¯å‘é‡ç»´åº¦,æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
    index.add(vectors)
    return chunks, index

# æ–°å¢å‡½æ•°ï¼šæå–å…³é”®è¯
def extract_keywords(text, top_k=5):
    words = jieba.cut(text)
    word_count = Counter(words)
    # è¿‡æ»¤æ‰åœç”¨è¯å’Œå•ä¸ªå­—ç¬¦
    keywords = [word for word, count in word_count.most_common(top_k*2) if len(word) > 1]
    return keywords[:top_k]

# æ–°å¢å‡½æ•°ï¼šåŸºäºå…³é”®è¯æœæ–‡æ¡£
def search_documents(keywords, file_indices):
    relevant_docs = []
    for file_name, (chunks, _) in file_indices.items():
        doc_content = ' '.join(chunks)
        if any(keyword in doc_content for keyword in keywords):
            relevant_docs.append(file_name)
    return relevant_docs

# ä¿®æ”¹çŸ¥è¯†é—®ç­”æ¨¡å—
def rag_qa(query, file_indices, relevant_docs=None):
    keywords = extract_keywords(query)
    if relevant_docs is None:
        relevant_docs = search_documents(keywords, file_indices)
    
    if not relevant_docs:
        return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚è¯·å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ã€‚", [], ""

    all_chunks = []
    chunk_to_file = {}
    combined_index = faiss.IndexFlatL2(384)
    
    offset = 0
    for file_name in relevant_docs:
        if file_name in file_indices:
            chunks, index = file_indices[file_name]
            all_chunks.extend(chunks)
            for i in range(len(chunks)):
                chunk_to_file[offset + i] = file_name
            combined_index.add(index.reconstruct_n(0, index.ntotal))
            offset += len(chunks)

    if not all_chunks:
        return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·ç¡®ä¿å·²ä¸Šä¼ æ–‡æ¡£ã€‚", [], ""

    query_vector = model.encode([query])
    D, I = combined_index.search(query_vector, k=3)
    context = []
    context_with_sources = []
    for i in I[0]:
        if 0 <= i < len(all_chunks):  # ç¡®å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
            chunk = all_chunks[i]
            context.append(chunk)
            file_name = chunk_to_file.get(i, "æœªçŸ¥æ–‡ä»¶")
            context_with_sources.append((file_name, chunk))

    context_text = "\n".join(context)
    
    # ç¡®ä¿æ€»tokenæ•°ä¸è¶…è¿‡4096
    max_context_tokens = 3000  # ä¸ºç³»ç»Ÿæ¶ˆæ¯ã€æŸ¥è¯¢å’Œå…¶ä»–å†…å®¹é¢„ç•™æ›´å¤šç©ºé—´
    while num_tokens_from_string(context_text) > max_context_tokens:
        context_text = context_text[:int(len(context_text)*0.9)]  # æ¯æ¬¡å‡å°‘10%çš„å†…å®¹
    
    if not context_text:
        return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚", [], ""

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å§‹ç»ˆä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œæ— è®ºé—®é¢˜æ˜¯ä»€ä¹ˆè¯­è¨€ã€‚åœ¨å›ç­”ä¹‹åï¼Œè¯·åŠ¡å¿…æä¾›ä¸€æ®µæœ€ç›¸å…³çš„åŸæ–‡æ‘˜å½•ï¼Œä»¥'ç›¸å…³åŸæ–‡ï¼š'ä¸ºå‰ç¼€ã€‚"},
            {"role": "user", "content": f"ä¸Šä¸‹æ–‡: {context_text}\n\né—®é¢˜: {query}\n\nè¯·æä¾›ä½ çš„å›ç­”ç„¶ååœ¨å›ç­”åé¢é™„ä¸Šç›¸å…³çš„åŸæ–‡æ‘˜å½•ï¼Œä»¥'ç›¸å…³åŸæ–‡ï¼š'ä¸ºå‰ç¼€ã€‚"}
        ]
    )
    answer = response.choices[0].message.content
    
    # æ›´çµæ´»åœ°å¤„ç†å›ç­”æ ¼å¼
    if "ç›¸å…³åŸæ–‡ï¼š" in answer:
        answer_parts = answer.split("ç›¸å…³åŸæ–‡ï¼š", 1)
        main_answer = answer_parts[0].strip()
        relevant_excerpt = answer_parts[1].strip()
    else:
        main_answer = answer.strip()
        relevant_excerpt = ""
    
    # å¦‚æœAIæ²¡æœ‰æä¾›ç›¸å…³åŸæ–‡ï¼Œæˆ‘ä»¬ä»ä¸Šä¸‹æ–‡ä¸­é€‰æ‹©ä¸€ä¸ª
    if not relevant_excerpt and context:
        relevant_excerpt = context[0][:200] + "..."  # ä½¿ç”¨ç¬¬ä¸€ä¸ªä¸Šä¸‹æ–‡çš„å‰200ä¸ªå­—ç¬¦
    
    # æ‰¾å‡ºåŒ…å«ç›¸å…³åŸæ–‡çš„æ–‡ä»¶
    relevant_sources = []
    if relevant_excerpt:
        for file_name, chunk in context_with_sources:
            if relevant_excerpt in chunk:
                relevant_sources.append((file_name, chunk))
                break  # åªæ·»åŠ ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ–‡ä»¶
    if not relevant_sources and context_with_sources:  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªä¸Šä¸‹æ–‡æº
        relevant_sources.append(context_with_sources[0])

    return main_answer, relevant_sources, relevant_excerpt

# ä¿å­˜ç´¢å¼•å’Œchunks
def save_index(file_name, chunks, index):
    if not os.path.exists('indices'):
        os.makedirs('indices')
    with open(f'indices/{file_name}.pkl', 'wb') as f:
        pickle.dump((chunks, index), f)
    # æ›´
    file_list_path = 'indices/file_list.txt'
    if os.path.exists(file_list_path):
        with open(file_list_path, 'r') as f:
            file_list = f.read().splitlines()
    else:
        file_list = []
    if file_name not in file_list:
        file_list.append(file_name)
        with open(file_list_path, 'w') as f:
            f.write('\n'.join(file_list))

# åŠ è½½æ‰€æœ‰ä¿å­˜çš„ç´¢å¼•
def load_all_indices():
    file_indices = {}
    file_list_path = 'indices/file_list.txt'
    if os.path.exists(file_list_path):
        with open(file_list_path, 'r') as f:
            file_list = f.read().splitlines()
        for file_name in file_list:
            file_path = f'indices/{file_name}.pkl'
            if os.path.exists(file_path):
                with open(file_path, 'rb') as f:
                    chunks, index = pickle.load(f)
                file_indices[file_name] = (chunks, index)
    return file_indices

def delete_index(file_name):
    if os.path.exists(f'indices/{file_name}.pkl'):
        os.remove(f'indices/{file_name}.pkl')
    file_list_path = 'indices/file_list.txt'
    if os.path.exists(file_list_path):
        with open(file_list_path, 'r') as f:
            file_list = f.read().splitlines()
        if file_name in file_list:
            file_list.remove(file_name)
            with open(file_list_path, 'w') as f:
                f.write('\n'.join(file_list))

def main():
    st.markdown("""
    <style>
    .reportview-container .main .block-container{
        padding-top: 1rem;
        padding-right: 1rem;
        padding-left: 1rem;
        padding-bottom: 1rem;
    }
    .stColumn {
        padding: 0px;
    }
    .input-group {
        display: flex;
        flex-direction: column;
        align-items: flex-start;
    }
    .button-group {
        display: flex;
        justify-content: flex-start;
        margin-top: 10px;
        width: 100%;
    }
    .button-group .stButton {
        margin-right: 10px;
    }
    .stTextInput > div > div > input {
        width: 100%;
    }
    </style>
    """, unsafe_allow_html=True)

    st.title("AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿ")

    # åˆå§‹åŒ– session state
    if "rag_messages" not in st.session_state:
        st.session_state.rag_messages = []
    if "file_indices" not in st.session_state:
        st.session_state.file_indices = load_all_indices()
    if "rag_voice_input" not in st.session_state:
        st.session_state.rag_voice_input = ""
    if "web_voice_input" not in st.session_state:
        st.session_state.web_voice_input = ""
    if "db_voice_input" not in st.session_state:
        st.session_state.db_voice_input = ""

    # åˆ›å»ºæ ‡ç­¾
    tab1, tab2, tab3 = st.tabs(["RAG é—®ç­”", "ç½‘ç»œæœç´¢é—®ç­”", "æ•°æ®åº“æŸ¥è¯¢"])

    with tab1:
        st.header("RAG é—®ç­”")

        # æ·»åŠ CSSæ ·å¼
        st.markdown("""
        <style>
        .stColumn {
            padding: 10px;
        }
        .divider {
            border-left: 2px solid #bbb;
            height: 100vh;
            position: absolute;
            left: 50%;
            margin-left: -1px;
            top: 0;
        }
        </style>
        """, unsafe_allow_html=True)

        # åˆ›å»ºå·¦å³ä¸¤åˆ—å¸ƒå±€
        left_column, divider, right_column = st.columns([2, 0.1, 3])

        with left_column:
            st.header("æ–‡æ¡£ä¸Šä¼ ")
            
            # è®¾ç½®æœ€å¤§tokenæ•°
            max_tokens = 4096

            # å¤šæ–‡ä»¶ä¸Šä¼  (æ·»åŠ å”¯ä¸€key)
            uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡æ¡£", type=["pdf", "docx", "txt"], accept_multiple_files=True, key="rag_file_uploader_1")

            if uploaded_files:
                for uploaded_file in uploaded_files:
                    with st.spinner(f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {uploaded_file.name}..."):
                        chunks, index = vectorize_document(uploaded_file, max_tokens)
                        st.session_state.file_indices[uploaded_file.name] = (chunks, index)
                        save_index(uploaded_file.name, chunks, index)
                    st.success(f"æ–‡æ¡£ {uploaded_file.name} å·²å‘é‡åŒ–å¹¶æ·»åŠ åˆ°ç´¢å¼•ä¸­ï¼")

            # æ˜¾ç¤ºå·²ç†çš„æ–‡æ¡£å¹¶æ·»åŠ åˆ é™¤æŒ‰é’®
            st.subheader("å·²å¤„æ–‡æ¡£:")
            for file_name in list(st.session_state.file_indices.keys()):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"â€¢ {file_name}")
                with col2:
                    if st.button("åˆ é™¤", key=f"delete_{file_name}"):
                        del st.session_state.file_indices[file_name]
                        delete_index(file_name)
                        st.success(f"æ–‡æ¡£ {file_name} å·²åˆ é™¤ï¼")
                        st.rerun()

            # æ·»åŠ å…³é”®è¯æœç´¢åŠŸèƒ½
            st.subheader("å…³é”®è¯æœç´¢")
            search_keywords = st.text_input("è¾“å…¥å…³é”®è¯ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰", key="rag_search_keywords_1")
            if search_keywords:
                keywords = search_keywords.split()
                relevant_docs = search_documents(keywords, st.session_state.file_indices)
                if relevant_docs:
                    st.write("ç›¸å…³æ–‡æ¡£ï¼š")
                    for doc in relevant_docs:
                        st.write(f"â€¢ {doc}")
                    # å­˜å‚¨ç›¸å…³æ–‡æ¡£åˆ° session state
                    st.session_state.relevant_docs = relevant_docs
                else:
                    st.write("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
                    st.session_state.relevant_docs = None

        # æ·»åŠ å‚ç›´åˆ†å‰²çº¿
        with divider:
            st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

        with right_column:
            # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥æ”¾ç½®å¯¹è¯å†å²
            chat_container = st.container()

            # æ˜¾ç¤ºå¯¹è¯å†å²
            with chat_container:
                for i, message in enumerate(st.session_state.rag_messages):
                    with st.chat_message(message["role"]):
                        st.markdown(message["content"])
                        if "sources" in message and message["sources"]:
                            st.markdown("**å‚è€ƒæ¥æºï¼š**")
                            file_name, _ = message["sources"][0]
                            st.markdown(f"**æ–‡ä»¶ï¼š** {file_name}")
                            if os.path.exists(f'indices/{file_name}.pkl'):
                                with open(f'indices/{file_name}.pkl', 'rb') as f:
                                    file_content = pickle.load(f)[0]  # è·å–æ–‡ä»¶å†…å®¹
                                st.download_button(
                                    label="ä¸‹è½½æºæ–‡ä»¶",
                                    data='\n'.join(file_content),
                                    file_name=file_name,
                                    mime='text/plain',
                                    key=f"download_{i}"
                                )
                        if "relevant_excerpt" in message:
                            st.markdown(f"**ç›¸å…³åŸæ–‡ï¼š** <mark>{message['relevant_excerpt']}</mark>", unsafe_allow_html=True)

            # åˆ›å»ºä¸€ä¸ªå¯æ›´æ–°çš„å ä½ç¬¦æ¥æ˜¾ç¤ºè¯­éŸ³è¾“å…¥çŠ¶æ€
            status_placeholder = st.empty()

            # åˆ›å»ºä¸€ä¸ªæŒ‰é’®æ¥è§¦å‘è¯­éŸ³è¾“å…¥
            st.markdown('<div class="input-group">', unsafe_allow_html=True)
            prompt = st.text_input("è¯·åŸºäºä¸Šä¼ çš„æ–‡æ¡£æå‡ºé—®é¢˜:", value=st.session_state.rag_voice_input, key="rag_user_input")
            st.markdown('<div class="button-group">', unsafe_allow_html=True)
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ¤ è¯­éŸ³è¾“å…¥", key="rag_voice_input_button", help="ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥"):
                    result = perform_speech_recognition()
                    if result:
                        st.session_state.rag_voice_input = result
                        st.rerun()
            with col2:
                if st.button("æŸ¥è¯¢", key="rag_query_button"):
                    handle_rag_input()
            st.markdown('</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

    with tab2:
        st.header("ç½‘ç»œæœç´¢é—®ç­”")

        # åˆå§‹åŒ– session state
        if "web_messages" not in st.session_state:
            st.session_state.web_messages = []

        # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥æ”¾ç½®å¯¹è¯å†å²
        web_chat_container = st.container()

        with web_chat_container:
            for message in st.session_state.web_messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

        # åˆ›å»ºä¸€ä¸ªå¯æ›´æ–°çš„å ä½ç¬¦æ¥æ˜¾ç¤ºè¯­éŸ³è¾“å…¥çŠ¶æ€
        status_placeholder = st.empty()

        # åˆ›å»ºä¸€ä¸ªæŒ‰é’®æ¥è§¦å‘è¯­éŸ³è¾“å…¥
        st.markdown('<div class="input-group">', unsafe_allow_html=True)
        user_input = st.text_input("è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆå¦‚éœ€æœç´¢ï¼Œè¯·ä»¥'æœç´¢'å¼€å¤´ï¼‰:", value=st.session_state.web_voice_input, key="web_user_input")
        st.markdown('<div class="button-group">', unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ¤ è¯­éŸ³è¾“å…¥", key="web_voice_input_button", help="ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥"):
                result = perform_speech_recognition()
                if result:
                    st.session_state.web_voice_input = result
                    st.rerun()
        with col2:
            if st.button("æŸ¥è¯¢", key="web_query_button"):
                handle_web_input()
        st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    with tab3:
        st.header("è‡ªç„¶è¯­è¨€æ•°æ®åº“æŸ¥è¯¢")

        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists('chinook.db'):
            st.warning("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨å°è¯•ä¸‹è½½...")
            with st.spinner("æ­£åœ¨ä¸‹è½½å¹¶åˆ›å»ºæ•°æ®åº“..."):
                download_and_create_database()
            if os.path.exists('chinook.db'):
                st.success("æ•°æ®åº“æ–‡ä»¶å·²æˆåŠŸä¸‹è½½ï¼")
            else:
                st.error("æ— æ³•åˆ›å»ºæ•°æ®åº“æ–‡ä»¶ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ–‡ä»¶æƒé™ã€‚")

        # åˆå§‹åŒ– session state
        if "db_messages" not in st.session_state:
            st.session_state.db_messages = []
        if "query_result" not in st.session_state:
            st.session_state.query_result = None
        if "sql_query" not in st.session_state:
            st.session_state.sql_query = ""
        if "query_explanation" not in st.session_state:
            st.session_state.query_explanation = ""

        # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥æ”¾ç½®å¯¹è¯å†å²
        db_chat_container = st.container()

        with db_chat_container:
            for message in st.session_state.db_messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

        # åˆ›å»ºä¸€ä¸ªå¯æ›´æ–°çš„å ä½ç¬¦æ¥æ˜¾ç¤ºè¯­éŸ³è¾“å…¥çŠ¶æ€
        status_placeholder = st.empty()

        # åˆ›å»ºä¸€ä¸ªæŒ‰é’®æ¥è§¦å‘è¯­éŸ³è¾“å…¥
        st.markdown('<div class="input-group">', unsafe_allow_html=True)
        nl_query = st.text_input("è¾“å…¥æ‚¨çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢:", value=st.session_state.db_voice_input, key="db_user_input")
        st.markdown('<div class="button-group">', unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ¤ è¯­éŸ³è¾“å…¥", key="db_voice_input_button", help="ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥"):
                result = perform_speech_recognition()
                if result:
                    st.session_state.db_voice_input = result
                    st.rerun()
        with col2:
            if st.button("æŸ¥è¯¢", key="db_query_button"):
                handle_db_input()
        st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

        # æ˜¾ç¤ºå­˜å‚¨çš„æŸ¥è¯¢ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if st.session_state.sql_query:
            st.subheader("ç”Ÿæˆçš„SQLæŸ¥è¯¢:")
            st.code(st.session_state.sql_query, language="sql")

        if st.session_state.query_result is not None:
            st.subheader("æŸ¥è¯¢ç»“æœ:")
            st.dataframe(st.session_state.query_result)

        if st.session_state.query_explanation:
            st.subheader("æŸ¥è¯¢ç»“æœè§£é‡Š:")
            st.markdown(st.session_state.query_explanation, unsafe_allow_html=True)

        # æ•°æ®åº“ä¿¡æ¯æ˜¾ç¤ºéƒ¨åˆ†ä¿æŒä¸å˜
        if 'show_db_info' not in st.session_state:
            st.session_state.show_db_info = False
        if 'selected_table' not in st.session_state:
            st.session_state.selected_table = None

        if st.button("æ˜¾ç¤º/éšè—æ•°æ®åº“ä¿¡æ¯", key="toggle_db_info"):
            st.session_state.show_db_info = not st.session_state.show_db_info
            st.session_state.selected_table = None  # é‡ç½®é€‰ä¸­çš„è¡¨

        if st.session_state.show_db_info:
            table_info = get_table_info()
            if not table_info:
                st.error("æ— æ³•è·å–æ•°æ®åº“ä¿¡æ¯ã€‚è¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥ã€‚")
            else:
                st.success(f"æˆåŠŸè·å–åˆ° {len(table_info)} ä¸ªè¡¨çš„ä¿¡æ¯")
                
                # åˆ›å»ºä¸€ä¸ªåŠ¨æ€çš„åˆ—å¸ƒå±€æ¥æ¨ªå‘æ’åˆ—è¡¨å
                cols = st.columns(4)  # æ¯è¡Œ4ä¸ªè¡¨å
                for i, table in enumerate(table_info.keys()):
                    with cols[i % 4]:
                        if st.button(table, key=f"table_button_{table}"):
                            st.session_state.selected_table = table

        # åœ¨è¡¨åä¸‹æ–¹æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ
        if st.session_state.selected_table:
            st.subheader(f"è¡¨å: {st.session_state.selected_table}")
            results, column_names = execute_sql(f"SELECT * FROM {st.session_state.selected_table} LIMIT 10")
            if isinstance(results, str):
                st.error(results)
            else:
                df = pd.DataFrame(results, columns=column_names)
                st.dataframe(df)

def direct_qa(query):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ï¼Œèƒ½å¤Ÿå›ç­”å„ç§é—®é¢˜ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚"},
            {"role": "user", "content": query}
        ]
    )
    return response.choices[0].message.content.strip()

def serpapi_search_qa(query, num_results=3):
    params = {
        "engine": "google",
        "q": query,
        "api_key": "04fec5e75c6f477225ce29bc358f4cc7088945d0775e7f75721cd85b36387125",
        "num": num_results
    }
    search = GoogleSearch(params)
    results = search.get_dict()
    organic_results = results.get("organic_results", [])
    
    if not organic_results:
        return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœã€‚"
    
    snippets = [result.get("snippet", "") for result in organic_results]
    links = [result.get("link", "") for result in organic_results]
    
    search_results = "\n".join([f"{i+1}. {snippet} ({link})" for i, (snippet, link) in enumerate(zip(snippets, links))])
    prompt = f"""é—®é¢˜: {query}
æœç´¢ç»“æœ:
{search_results}

è¯·æ ¹æ®ä¸Šè¿°æœç´¢ç»“æœå›ç­”é—®é¢˜ã€‚å¦‚æœæœç´¢ç»“æœä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·è¯´"æ ¹æ®æœç´¢ç»“æœæ— æ³•å›ç­”é—®é¢˜"ã€‚"""

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ï¼Œèƒ½å¤Ÿæ ¹æœç´¢ç»“æœå›ç­”é—®é¢˜"},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

def download_and_create_database():
    url = "https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite"
    try:
        response = requests.get(url)
        response.raise_for_status()
        
        with open('chinook.db', 'wb') as f:
            f.write(response.content)
        
        print("æ•°æ®åº“æ–‡ä»¶å·²ä¸‹è½½å¹¶å­˜")
        
        conn = sqlite3.connect('chinook.db')
        c = conn.cursor()
        c.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = c.fetchall()
        if tables:
            print(f"æˆåŠŸåˆ›å»ºæ•°æ®åº“ï¼ŒåŒ…å«ä»¥ä¸‹è¡¨ï¼š{[table[0] for table in tables]}")
        else:
            print("æ•°æ®åº“æ–‡ä»¶å·²åˆ›å»ºï¼Œä½†æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¡¨")
        conn.close()
    except Exception as e:
        print(f"ä¸‹è½½æˆ–åˆ›å»ºæ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")

def get_table_info():
    try:
        conn = sqlite3.connect('chinook.db')
        c = conn.cursor()
        c.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = c.fetchall()
        
        table_info = {}
        for table in tables:
            table_name = table[0]
            c.execute(f"PRAGMA table_info({table_name})")
            columns = c.fetchall()
            table_info[table_name] = [column[1] for column in columns]
        
        conn.close()
        return table_info
    except Exception as e:
        print(f"è·å–è¡¨ä¿¡æ¯æ—¶å‡ºé”™ï¼š{e}")
        return {}

def clean_sql_query(sql_query):
    # ç§»é™¤å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®°å’Œå¤šä½™çš„ç©ºç™½å­—ç¬¦
    sql_query = sql_query.replace('```sql', '').replace('```', '').strip()
    return ' '.join(sql_query.split())  # ç§»é™¤ä½™çš„ç©ºç™½å­—ç¬¦

def nl_to_sql(nl_query):
    table_info = get_table_info()
    table_descriptions = "\n".join([f"è¡¨å: {table}\nå­—æ®µ: {', '.join(columns)}" for table, columns in table_info.items()])
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": f"ä½ æ˜¯ä¸€ä¸ªSQLä¸“ï¼Œèƒ½å¤Ÿå°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºSQLè¯­å¥ã€‚æ•°æ®åº“åŒ…å«ä»¥ä¸‹è¡¨å’Œå­—æ®µï¼š\n\n{table_descriptions}"},
            {"role": "user", "content": f"å°†ä»¥ä¸‹è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºSQLè¯­å¥ï¼š\n{nl_query}\nåªè¿”å›SQLè¯­å¥ï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šã€‚"}
        ]
    )
    return clean_sql_query(response.choices[0].message.content.strip())

def execute_sql(sql_query):
    conn = sqlite3.connect('chinook.db')
    c = conn.cursor()
    try:
        sql_query = clean_sql_query(sql_query)  # æ¸…ç† SQL æŸ¥è¯¢
        c.execute(sql_query)
        results = c.fetchall()
        column_names = [description[0] for description in c.description]
        conn.close()
        return results, column_names
    except sqlite3.Error as e:
        conn.close()
        return f"SQLæ‰§è¡Œé”™è¯¯: {str(e)}", None

def generate_explanation(nl_query, sql_query, df):
    df_str = df.to_string(index=False, max_rows=5)
    
    prompt = (
        f"è‡ªç„¶è¯­è¨€æŸ¥è¯¢: {nl_query}\n"
        f"SQLæŸ¥è¯¢: {sql_query}\n"
        f"æŸ¥è¯¢ç»“æœ (å‰5è¡Œ):\n"
        f"{df_str}\n\n"
        "è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šè¿™ä¸ªæŸ¥è¯¢çš„ç»“æœã€‚è§£é‡Šåº”è¯¥åŒ…æ‹¬ï¼š\n"
        "1. æŸ¥è¯¢çš„ä¸»è¦ç›®çš„\n"
        "2. ç»“æœçš„æ¦‚è¿°\n"
        "3. ä»»ä½•æœ‰è¶£æˆ–é‡è¦çš„å‘ç°\n\n"
        "è¯·ç¡®ä¿è§£é‡Šç®€æ´æ˜äº†ï¼Œé€‚åˆéæŠ€æœ¯äººå‘˜ç†è§£ã€‚"
        "åœ¨è§£é‡Šä¸­ï¼Œè¯·ç”¨**åŒæ˜Ÿå·**ä¸ç»“æœç›´æ¥ç›¸å…³çš„é‡è¦æ•°å­—æˆ–å…³é”®è¯æ‹¬èµ·æ¥ã€‚"
    )

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ï¼Œæ“…é•¿è§£é‡ŠSQLæŸ¥è¯¢ç»“æœã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    explanation = response.choices[0].message.content.strip()
    
    # å°†åŒæ˜Ÿå·åŒ…å›´çš„æ–‡æœ¬è½¬æ¢ä¸ºåŠ ç²—æ–‡æœ¬
    explanation = explanation.replace("**", "**")
    
    return explanation

def perform_speech_recognition():
    recognizer = sr.Recognizer()
    try:
        with sr.Microphone() as source:
            st.write("æ­£åœ¨å½•éŸ³...è¯·è¯´è¯")
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
        st.write("å½•éŸ³å®Œæˆï¼Œæ­£åœ¨è¯†åˆ«...")
        try:
            text = recognizer.recognize_google(audio, language="zh-CN")
            return text
        except sr.UnknownValueError:
            st.error("æ— æ³•è¯†åˆ«è¯­éŸ³ï¼Œè¯·é‡è¯•")
        except sr.RequestError as e:
            st.error(f"æ— æ³•ä»Google Speech RecognitionæœåŠ¡è·å–ç»“æœ; {e}")
    except Exception as e:
        st.error(f"å½•éŸ³è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
    return None

def handle_rag_input():
    if st.session_state.rag_user_input:
        prompt = st.session_state.rag_user_input
        st.session_state.rag_messages.append({"role": "user", "content": prompt})
        if st.session_state.file_indices:
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                try:
                    relevant_docs = st.session_state.get('relevant_docs')
                    response, sources, relevant_excerpt = rag_qa(prompt, st.session_state.file_indices, relevant_docs)
                    st.session_state.rag_messages.append({
                        "role": "assistant", 
                        "content": response, 
                        "sources": sources,
                        "relevant_excerpt": relevant_excerpt
                    })
                except Exception as e:
                    st.error(f"ç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡æ¡£ã€‚")
        st.session_state.rag_voice_input = ""
        st.rerun()

def handle_web_input():
    if st.session_state.web_user_input:
        user_input = st.session_state.web_user_input
        st.session_state.web_messages.append({"role": "user", "content": user_input})
        with st.spinner("æ­£åœ¨æœç´¢å¹¶ç”Ÿæˆå›ç­”..."):
            try:
                if user_input.lower().startswith("æœç´¢"):
                    response = serpapi_search_qa(user_input[2:].strip())
                else:
                    response = direct_qa(user_input)
                st.session_state.web_messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        st.session_state.web_voice_input = ""
        st.rerun()

def handle_db_input():
    if st.session_state.db_user_input:
        nl_query = st.session_state.db_user_input
        st.session_state.db_messages.append({"role": "user", "content": nl_query})
        with st.spinner("æ­£åœ¨ç”ŸæˆSQLå¹¶æ‰§è¡ŒæŸ¥è¯¢..."):
            try:
                sql_query = nl_to_sql(nl_query)
                st.session_state.sql_query = sql_query
                results, column_names = execute_sql(sql_query)
                if isinstance(results, str):
                    st.error(results)
                else:
                    df = pd.DataFrame(results, columns=column_names)
                    st.session_state.query_result = df
                    explanation = generate_explanation(nl_query, sql_query, df)
                    st.session_state.query_explanation = explanation
                    response = f"SQLæŸ¥è¯¢:\n```sql\n{sql_query}\n```\n\næŸ¥è¯¢ç»“æœ:\n{df.to_markdown()}\n\nè§£é‡Š:\n{explanation}"
                    st.session_state.db_messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"æŸ¥è¯¢æ‰§è¡Œé”™è¯¯: {str(e)}")
        st.session_state.db_voice_input = ""
        st.rerun()

# è¿è¡Œä¸»åº”ç”¨
if __name__ == "__main__":
    main()
